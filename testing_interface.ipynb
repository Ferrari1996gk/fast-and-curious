{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Interface\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This repository contains a number of different independent projects. Each project is entirely separate from the others. Your goal is to optimise the code of each project. For each project there are three versions of the code:\n",
    "\n",
    "* A base version that is complete and fully functional, but may not be very fast. This is contained in the ```base``` directory.\n",
    "* An optimized version that is complete and fully functional, and is optimized for speed. This is contained in the ```sample_solution``` directory.\n",
    "* A version that is identical to the version in ```base```. This is the version you will work on to optimise. This is contained in the ```student``` directory.\n",
    "\n",
    "You should only edit the code in the ```student``` directory. In this file you will find descriptions each each project, and code which can run the tests for each project. You will gain points for each project depending on how much you have sped it up compared to the base version.\n",
    "\n",
    "## Scoring\n",
    "\n",
    "Each project will be tested with a number of different cases. Each case will pass a set of inputs to your code and and time it. The output of your code will also be tested for correctness. For each case, you will be awarded points according to the formula:\n",
    "\n",
    "$$\n",
    "p_{case} = \\max\\left(0, \\log_{10}\\left(\\frac{t_{base}}{t_{student}}\\right)\\right)\n",
    "$$\n",
    "\n",
    "where $p_{case}$ is the number of points you will be awarded for that case, $t_{base}$ is the time taken by the base version of the code, and $t_{student}$ is the time taken by your version of the code. This means that if your code is 10x faster than the base version, you will get 1 point. If your code is 100x faster than the base version, you will get 2 points. If your code is slower than the base version, you will get 0 points. \n",
    "\n",
    "Because the ratio of the time it takes for your code to run to the time it takes for the base code to run is used, the points you receive will approximately be the same regardless of the machine on which the code is run. Note that, if you re-run the tests on your machine, you may get different results each time, as a piece of code will have some variation in how long it takes to run.\n",
    "\n",
    "Once all cases have been run, you will gain a number of points for the project equal to the average of $p_{case}$ over all cases. If any case fails the check for correctness, you will receive 0 points for the whole project.\n",
    "\n",
    "Overall, you will receive a number of points equal to the sum of the points awarded for each project.\n",
    "\n",
    "## Rules/Guidance\n",
    "\n",
    "You may use a wide variety of tools and approaches to speed up the code. You may, in particular, want to considering using profiling tools to help you understand where the code is spending most of its time. You may use any module from the Python standard library, but may only use the other packages as specified in the file ```requirements.txt``` in the base directory of the project. You should avoid changing the interface of the main function being called for each project, as this will break the tests. You may, however, create new functions, classes or files, or reorganise existing ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primes Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your solution found 1229 primes, but it should have found 168 primes.\n",
      "===================================\n",
      "Project: Primes\n",
      "Description: Write primes under n to a specified file.\n",
      "Case: Writing primes under 1,000\n",
      "Base Time: 0.1369s\n",
      "Sample Solution Time: 0.0024s\n",
      "Your Success: True\n",
      "Your Time: 0.0984s\n",
      "Points: 0.1433\n",
      "-----------------------------------\n",
      "Case: Writing primes under 10,000\n",
      "Base Time: 1.2563s\n",
      "Sample Solution Time: 0.0926s\n",
      "Your Success: False\n",
      "Your Time: 1.0169s\n",
      "Points: 0.0000e+00\n",
      "-----------------------------------\n",
      "Average Points: 0.0717 for Case \"Primes\"\n",
      "===================================\n",
      "Total Points: 0.0717\n"
     ]
    }
   ],
   "source": [
    "from tests import run_tests\n",
    "\n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
